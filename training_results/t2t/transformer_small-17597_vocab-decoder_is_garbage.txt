WARNING: Logging before flag parsing goes to stderr.
W0916 21:45:54.788475 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0916 21:45:55.493429 139906052065152 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0916 21:45:57.111689 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

W0916 21:45:57.112106 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0916 21:45:57.119033 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.

W0916 21:45:57.119232 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

W0916 21:45:57.167438 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:105: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.

W0916 21:45:57.738360 139906052065152 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:32: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0916 21:45:57.738651 139906052065152 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:32: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0916 21:45:57.738842 139906052065152 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:33: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

:::MLPv0.5.0 transformer 1568670358.003151894 (/usr/local/bin/t2t-trainer:28) run_set_random_seed
I0916 21:45:58.003191 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670358.003151894 (/usr/local/bin/t2t-trainer:28) run_set_random_seed
W0916 21:45:58.003563 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:789: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

W0916 21:45:58.004823 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/usr_dir.py:42: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

I0916 21:45:58.004954 139906052065152 usr_dir.py:43] Importing user module 810a33b852eff8689b46cbb5540f5bd9 from path /content
W0916 21:45:58.005714 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:142: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

W0916 21:45:58.006290 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:117: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.

W0916 21:45:58.006515 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:123: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

W0916 21:45:58.006849 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:278: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.
Instructions for updating:
When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.
I0916 21:45:58.007062 139906052065152 trainer_lib.py:301] Configuring DataParallelism to replicate the model.
I0916 21:45:58.007189 139906052065152 devices.py:76] schedule=continuous_train_and_eval
I0916 21:45:58.007291 139906052065152 devices.py:77] worker_gpu=1
I0916 21:45:58.007389 139906052065152 devices.py:78] sync=False
W0916 21:45:58.007560 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/devices.py:139: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.

W0916 21:45:58.007672 139906052065152 devices.py:141] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.
I0916 21:45:58.008339 139906052065152 devices.py:170] datashard_devices: ['gpu:0']
I0916 21:45:58.008465 139906052065152 devices.py:171] caching_devices: None
I0916 21:45:58.008932 139906052065152 devices.py:172] ps_devices: ['gpu:0']
W0916 21:45:58.009200 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/text_encoder.py:942: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.

I0916 21:45:58.117424 139906052065152 estimator.py:209] Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3e0e123b10>, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {
  per_process_gpu_memory_fraction: 0.95
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: OFF
  }
}
, '_model_dir': '/content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f3e0e123b50>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}
W0916 21:45:58.117821 139906052065152 model_fn.py:630] Estimator's model_fn (<function wrapping_model_fn at 0x7f3e0ea0d758>) includes params argument, but params are not passed to Estimator.
W0916 21:45:58.118459 139906052065152 trainer_lib.py:722] ValidationMonitor only works with --schedule=train_and_evaluate
W0916 21:45:58.119146 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py:310: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

I0916 21:45:58.575664 139906052065152 estimator_training.py:186] Not using Distribute Coordinator.
I0916 21:45:58.576102 139906052065152 training.py:612] Running training and evaluation locally (non-distributed).
I0916 21:45:58.576571 139906052065152 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.
W0916 21:45:58.590425 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLPv0.5.0 transformer 1568670358.604291916 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 21:45:58.604315 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670358.604291916 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 21:45:58.604563 139906052065152 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-train*
I0916 21:45:58.606395 139906052065152 problem.py:644] partition: 0 num_data_files: 100
:::MLPv0.5.0 transformer 1568670358.607294083 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:872) input_order
I0916 21:45:58.607342 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670358.607294083 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:872) input_order
W0916 21:45:58.609679 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:654: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
W0916 21:45:58.609869 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0916 21:45:58.681310 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:172: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
W0916 21:45:58.696017 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:31: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0916 21:45:58.725986 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:947: bucket_by_sequence_length (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.bucket_by_sequence_length(...)`.
W0916 21:45:58.748491 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/data/experimental/ops/grouping.py:193: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0916 21:45:58.809535 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:1209: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0916 21:45:58.821530 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:1211: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
I0916 21:45:58.883255 139906052065152 estimator.py:1145] Calling model_fn.
:::MLPv0.5.0 transformer 1568670359.334177017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 21:45:59.334217 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670359.334177017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 21:45:59.334531 139906052065152 t2t_model.py:1905] Setting T2TModel mode to 'train'
W0916 21:45:59.425820 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:167: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.

:::MLPv0.5.0 transformer 1568670361.783919096 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
W0916 21:46:04.179847 139906052065152 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7f3e3316d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.
I0916 21:46:02.569638 139906052065152 api.py:452] :::MLPv0.5.0 transformer 1568670361.783919096 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
I0916 21:46:04.180792 139906052065152 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 21:46:04.707391 139906052065152 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_17594_256.bottom
I0916 21:46:04.878230 139906052065152 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_17594_256.targets_bottom
I0916 21:46:04.903726 139906052065152 t2t_model.py:1905] Building model body
:::MLPv0.5.0 transformer 1568670364.998425961 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.1
I0916 21:46:04.998456 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670364.998425961 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.1
W0916 21:46:04.998826 139906052065152 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:92: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
:::MLPv0.5.0 transformer 1568670365.011265039 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
I0916 21:46:05.011281 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670365.011265039 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568670365.012514114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.1
I0916 21:46:05.012528 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670365.012514114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.1
:::MLPv0.5.0 transformer 1568670365.013854027 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 21:46:05.013870 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670365.013854027 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
W0916 21:46:05.053603 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_layers.py:2926: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0916 21:46:05.508081 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_attention.py:1171: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

:::MLPv0.5.0 transformer 1568670365.601124048 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 21:46:05.601155 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670365.601124048 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568670365.602493048 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 21:46:05.602514 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670365.602493048 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670365.603776932 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1
I0916 21:46:05.603792 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670365.603776932 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1
:::MLPv0.5.0 transformer 1568670366.250026941 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 21:46:06.250061 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670366.250026941 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568670366.251358986 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 21:46:06.251374 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670366.251358986 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670366.252553940 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1
I0916 21:46:06.252571 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670366.252553940 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1
:::MLPv0.5.0 transformer 1568670366.370928049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
I0916 21:46:06.370958 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670366.370928049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
:::MLPv0.5.0 transformer 1568670366.481286049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.1
I0916 21:46:06.481316 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670366.481286049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.1
:::MLPv0.5.0 transformer 1568670366.498537064 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
I0916 21:46:06.498581 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670366.498537064 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568670366.501354933 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.1
I0916 21:46:06.501379 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670366.501354933 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.1
:::MLPv0.5.0 transformer 1568670366.503077030 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 21:46:06.503094 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670366.503077030 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670367.034408092 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 21:46:07.034439 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670367.034408092 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568670367.035721064 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 21:46:07.035737 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670367.035721064 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670367.036998034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1
I0916 21:46:07.037013 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670367.036998034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1
:::MLPv0.5.0 transformer 1568670367.955369949 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 21:46:07.955401 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670367.955369949 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568670367.956790924 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 21:46:07.956808 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670367.956790924 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670367.958000898 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1
I0916 21:46:07.958014 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670367.958000898 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1
:::MLPv0.5.0 transformer 1568670368.058651924 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 21:46:08.058679 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670368.058651924 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 21:46:08.091027 139906052065152 t2t_model.py:1905] Transforming body output with symbol_modality_17594_256.top
:::MLPv0.5.0 transformer 1568670368.223505020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate: "DEFERRED: 4fb0645c-7667-47af-9611-b214ca796115"
I0916 21:46:08.223531 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670368.223505020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate: "DEFERRED: 4fb0645c-7667-47af-9611-b214ca796115"
:::MLPv0.5.0 transformer 1568670368.224508047 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate_warmup_steps: 8000
I0916 21:46:08.224524 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670368.224508047 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate_warmup_steps: 8000
W0916 21:46:08.224764 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/learning_rate.py:100: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

I0916 21:46:08.226762 139906052065152 learning_rate.py:29] Base learning rate: 2.000000
I0916 21:46:08.244741 139906052065152 optimize.py:251] Trainable Variables Total size: 8193536
I0916 21:46:08.245085 139906052065152 optimize.py:251] Non-trainable variables Total size: 5
I0916 21:46:08.245332 139906052065152 optimize.py:89] Using optimizer Adam
:::MLPv0.5.0 transformer 1568670368.246269941 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_name: "Adam"
I0916 21:46:08.246303 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670368.246269941 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_name: "Adam"
:::MLPv0.5.0 transformer 1568670368.247411013 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta1: 0.9
I0916 21:46:08.247426 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670368.247411013 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta1: 0.9
:::MLPv0.5.0 transformer 1568670368.248327017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta2: 0.997
I0916 21:46:08.248341 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670368.248327017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta2: 0.997
:::MLPv0.5.0 transformer 1568670368.249340057 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_epsilon: 1e-09
I0916 21:46:08.249353 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670368.249340057 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_epsilon: 1e-09
I0916 21:46:13.325443 139906052065152 estimator.py:1147] Done calling model_fn.
I0916 21:46:13.327128 139906052065152 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
I0916 21:46:15.497473 139906052065152 monitored_session.py:240] Graph was finalized.
2019-09-16 21:46:15.504329: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-09-16 21:46:15.504662: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55debb735500 executing computations on platform Host. Devices:
2019-09-16 21:46:15.504697: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-16 21:46:15.526241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-16 21:46:15.608411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:46:15.609396: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55debb735880 executing computations on platform CUDA. Devices:
2019-09-16 21:46:15.609438: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-09-16 21:46:15.609748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:46:15.610609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-09-16 21:46:15.611206: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 21:46:15.612932: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 21:46:15.614322: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-16 21:46:15.614754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-16 21:46:15.616782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-16 21:46:15.618113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-16 21:46:15.622115: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 21:46:15.622251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:46:15.623045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:46:15.623745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 21:46:15.623870: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 21:46:15.625589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 21:46:15.625637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 21:46:15.625653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 21:46:15.625817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:46:15.626585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:46:15.627263: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2019-09-16 21:46:15.627332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2019-09-16 21:46:16.420533: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0916 21:46:17.264182 139906052065152 session_manager.py:500] Running local_init_op.
I0916 21:46:17.366168 139906052065152 session_manager.py:502] Done running local_init_op.
I0916 21:46:22.607256 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
2019-09-16 21:46:27.419836: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 21:46:37.670181: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 250 of 512
2019-09-16 21:46:47.706869: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.
I0916 21:46:48.016980 139906052065152 basic_session_run_hooks.py:262] loss = 8.752595, step = 0
I0916 21:47:11.726197 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21734
I0916 21:47:11.727873 139906052065152 basic_session_run_hooks.py:260] loss = 7.019487, step = 100 (23.711 sec)
I0916 21:47:32.611638 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.78804
I0916 21:47:32.613502 139906052065152 basic_session_run_hooks.py:260] loss = 5.673197, step = 200 (20.886 sec)
I0916 21:47:53.171120 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.86393
I0916 21:47:53.173187 139906052065152 basic_session_run_hooks.py:260] loss = 4.6713867, step = 300 (20.560 sec)
I0916 21:48:14.203423 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.75459
I0916 21:48:14.205431 139906052065152 basic_session_run_hooks.py:260] loss = 4.134608, step = 400 (21.032 sec)
I0916 21:48:35.206701 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.76116
I0916 21:48:35.208724 139906052065152 basic_session_run_hooks.py:260] loss = 3.7954507, step = 500 (21.003 sec)
I0916 21:48:56.345499 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.73063
I0916 21:48:56.348100 139906052065152 basic_session_run_hooks.py:260] loss = 3.5468879, step = 600 (21.139 sec)
I0916 21:49:18.072624 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.60255
I0916 21:49:18.075016 139906052065152 basic_session_run_hooks.py:260] loss = 3.313934, step = 700 (21.727 sec)
I0916 21:49:40.024499 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.55541
I0916 21:49:40.027101 139906052065152 basic_session_run_hooks.py:260] loss = 3.1198282, step = 800 (21.952 sec)
I0916 21:50:01.685060 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.6167
I0916 21:50:01.687189 139906052065152 basic_session_run_hooks.py:260] loss = 2.7863176, step = 900 (21.660 sec)
I0916 21:50:23.288695 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 1000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
:::MLPv0.5.0 transformer 1568670624.187866926 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 21:50:24.187901 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670624.187866926 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 21:50:24.188222 139906052065152 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*
I0916 21:50:24.189759 139906052065152 problem.py:644] partition: 0 num_data_files: 1
I0916 21:50:24.413944 139906052065152 estimator.py:1145] Calling model_fn.
:::MLPv0.5.0 transformer 1568670624.868221045 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 21:50:24.868259 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670624.868221045 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 21:50:24.868590 139906052065152 t2t_model.py:1905] Setting T2TModel mode to 'eval'
I0916 21:50:24.868808 139906052065152 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0
I0916 21:50:24.868916 139906052065152 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0
I0916 21:50:24.869005 139906052065152 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0
I0916 21:50:24.869106 139906052065152 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0
I0916 21:50:24.869188 139906052065152 t2t_model.py:1905] Setting hparams.dropout to 0.0
I0916 21:50:24.869270 139906052065152 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0
:::MLPv0.5.0 transformer 1568670624.987979889 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
W0916 21:50:25.008203 139906052065152 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7f3e3316d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.
I0916 21:50:24.990341 139906052065152 api.py:452] :::MLPv0.5.0 transformer 1568670624.987979889 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
I0916 21:50:25.009047 139906052065152 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 21:50:25.108716 139906052065152 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_17594_256.bottom
I0916 21:50:25.293601 139906052065152 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_17594_256.targets_bottom
I0916 21:50:25.319808 139906052065152 t2t_model.py:1905] Building model body
:::MLPv0.5.0 transformer 1568670625.837663889 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
I0916 21:50:25.837697 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670625.837663889 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568670625.839576006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
I0916 21:50:25.839592 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670625.839576006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568670625.841219902 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
I0916 21:50:25.841237 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670625.841219902 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568670625.842808008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 21:50:25.842824 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670625.842808008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670626.141467094 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 21:50:26.141499 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.141467094 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568670626.143162966 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 21:50:26.143178 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.143162966 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670626.144711971 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 21:50:26.144726 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.144711971 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568670626.507961035 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 21:50:26.507992 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.507961035 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568670626.510063887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 21:50:26.510087 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.510063887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670626.511857033 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 21:50:26.511873 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.511857033 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568670626.616131067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
I0916 21:50:26.616152 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.616131067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
:::MLPv0.5.0 transformer 1568670626.731873035 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
I0916 21:50:26.731904 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.731873035 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568670626.733908892 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
I0916 21:50:26.733926 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.733908892 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568670626.735479116 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
I0916 21:50:26.735496 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.735479116 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568670626.737042904 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 21:50:26.737057 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670626.737042904 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670627.278913975 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 21:50:27.278960 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670627.278913975 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568670627.280683041 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 21:50:27.280700 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670627.280683041 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670627.282243013 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 21:50:27.282258 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670627.282243013 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568670627.892802954 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 21:50:27.892836 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670627.892802954 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568670627.894607067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 21:50:27.894623 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670627.894607067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568670627.896177053 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 21:50:27.896192 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670627.896177053 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568670627.981267929 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 21:50:27.981288 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568670627.981267929 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 21:50:28.014395 139906052065152 t2t_model.py:1905] Transforming body output with symbol_modality_17594_256.top
W0916 21:50:28.170466 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0916 21:50:28.172312 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/metrics.py:553: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W0916 21:50:29.340612 139906052065152 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:1501: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

I0916 21:50:29.343003 139906052065152 estimator.py:1147] Done calling model_fn.
I0916 21:50:29.365139 139906052065152 evaluation.py:255] Starting evaluation at 2019-09-16T21:50:29Z
I0916 21:50:30.308758 139906052065152 monitored_session.py:240] Graph was finalized.
2019-09-16 21:50:30.310009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:50:30.310744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-09-16 21:50:30.310862: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 21:50:30.310927: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 21:50:30.310971: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-16 21:50:30.311012: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-16 21:50:30.311057: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-16 21:50:30.311100: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-16 21:50:30.311142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 21:50:30.311261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:50:30.311958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:50:30.312560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 21:50:30.312618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 21:50:30.312640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 21:50:30.312654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 21:50:30.312802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:50:30.313466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 21:50:30.314105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
W0916 21:50:30.314356 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
I0916 21:50:30.316071 139906052065152 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-1000
I0916 21:50:30.741328 139906052065152 session_manager.py:500] Running local_init_op.
I0916 21:50:30.829607 139906052065152 session_manager.py:502] Done running local_init_op.
I0916 21:50:34.321408 139906052065152 evaluation.py:167] Evaluation [10/100]
I0916 21:50:36.160799 139906052065152 evaluation.py:167] Evaluation [20/100]
I0916 21:50:37.892435 139906052065152 evaluation.py:275] Finished evaluation at 2019-09-16-21:50:37
I0916 21:50:37.892914 139906052065152 estimator.py:2039] Saving dict for global step 1000: global_step = 1000, loss = 2.733069, metrics-translate_enasl/targets/accuracy = 0.6038988, metrics-translate_enasl/targets/accuracy_per_sequence = 0.022982884, metrics-translate_enasl/targets/accuracy_top5 = 0.7194207, metrics-translate_enasl/targets/approx_bleu_score = 0.2943027, metrics-translate_enasl/targets/neg_log_perplexity = -2.700146, metrics-translate_enasl/targets/rouge_2_fscore = 0.37387338, metrics-translate_enasl/targets/rouge_L_fscore = 0.59846216
I0916 21:50:37.893749 139906052065152 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1000: /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-1000
I0916 21:50:38.090181 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 2.74687
I0916 21:50:38.092659 139906052065152 basic_session_run_hooks.py:260] loss = 2.5456464, step = 1000 (36.405 sec)
I0916 21:51:00.398796 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.48258
I0916 21:51:00.401201 139906052065152 basic_session_run_hooks.py:260] loss = 2.2976391, step = 1100 (22.309 sec)
I0916 21:51:22.628849 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.49841
I0916 21:51:22.631052 139906052065152 basic_session_run_hooks.py:260] loss = 2.1539938, step = 1200 (22.230 sec)
I0916 21:51:44.837934 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.50267
I0916 21:51:44.840337 139906052065152 basic_session_run_hooks.py:260] loss = 1.8420756, step = 1300 (22.209 sec)
I0916 21:52:07.141094 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.48367
I0916 21:52:07.143650 139906052065152 basic_session_run_hooks.py:260] loss = 1.730964, step = 1400 (22.303 sec)
I0916 21:52:29.433082 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.48593
I0916 21:52:29.435693 139906052065152 basic_session_run_hooks.py:260] loss = 1.5379666, step = 1500 (22.292 sec)
I0916 21:52:51.754828 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.47992
I0916 21:52:51.757236 139906052065152 basic_session_run_hooks.py:260] loss = 1.2724572, step = 1600 (22.322 sec)
I0916 21:53:14.424598 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.41119
I0916 21:53:14.427222 139906052065152 basic_session_run_hooks.py:260] loss = 1.169635, step = 1700 (22.670 sec)
I0916 21:53:36.624994 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.50442
I0916 21:53:36.629322 139906052065152 basic_session_run_hooks.py:260] loss = 0.5210945, step = 1800 (22.202 sec)
I0916 21:53:59.011989 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.46687
I0916 21:53:59.014256 139906052065152 basic_session_run_hooks.py:260] loss = 0.6870697, step = 1900 (22.385 sec)
I0916 21:54:21.122771 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 2000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 21:54:22.066644 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 21:54:22.306658 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.29283
I0916 21:54:22.308368 139906052065152 basic_session_run_hooks.py:260] loss = 0.6942379, step = 2000 (23.294 sec)
I0916 21:54:45.033611 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.40006
I0916 21:54:45.036148 139906052065152 basic_session_run_hooks.py:260] loss = 0.6210045, step = 2100 (22.728 sec)
I0916 21:55:07.592647 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.43281
I0916 21:55:07.594517 139906052065152 basic_session_run_hooks.py:260] loss = 0.4611879, step = 2200 (22.558 sec)
I0916 21:55:30.230667 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.41736
I0916 21:55:30.232963 139906052065152 basic_session_run_hooks.py:260] loss = 1.3243946, step = 2300 (22.638 sec)
I0916 21:55:52.621740 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.46606
I0916 21:55:52.626089 139906052065152 basic_session_run_hooks.py:260] loss = 0.32630962, step = 2400 (22.393 sec)
I0916 21:56:15.558953 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.35972
I0916 21:56:15.561671 139906052065152 basic_session_run_hooks.py:260] loss = 0.4208999, step = 2500 (22.936 sec)
I0916 21:56:38.386116 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.38075
I0916 21:56:38.388870 139906052065152 basic_session_run_hooks.py:260] loss = 0.33348206, step = 2600 (22.827 sec)
I0916 21:57:00.965853 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.42875
I0916 21:57:00.968902 139906052065152 basic_session_run_hooks.py:260] loss = 1.0298847, step = 2700 (22.580 sec)
I0916 21:57:23.706258 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.39746
I0916 21:57:23.707967 139906052065152 basic_session_run_hooks.py:260] loss = 0.3518555, step = 2800 (22.739 sec)
I0916 21:57:46.485388 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.38999
I0916 21:57:46.487726 139906052065152 basic_session_run_hooks.py:260] loss = 0.22215874, step = 2900 (22.780 sec)
I0916 21:58:08.997502 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 3000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 21:58:09.885826 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 21:58:10.149842 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.22575
I0916 21:58:10.151998 139906052065152 basic_session_run_hooks.py:260] loss = 0.30021527, step = 3000 (23.664 sec)
I0916 21:58:33.013843 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.37371
I0916 21:58:33.019525 139906052065152 basic_session_run_hooks.py:260] loss = 0.16462834, step = 3100 (22.868 sec)
I0916 21:58:55.558403 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.43564
I0916 21:58:55.560954 139906052065152 basic_session_run_hooks.py:260] loss = 0.23621644, step = 3200 (22.541 sec)
I0916 21:59:18.335717 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.39034
I0916 21:59:18.338684 139906052065152 basic_session_run_hooks.py:260] loss = 0.1943658, step = 3300 (22.778 sec)
I0916 21:59:41.511169 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.31489
I0916 21:59:41.513345 139906052065152 basic_session_run_hooks.py:260] loss = 0.1641394, step = 3400 (23.175 sec)
I0916 22:00:04.134656 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.4202
I0916 22:00:04.137697 139906052065152 basic_session_run_hooks.py:260] loss = 0.18182749, step = 3500 (22.624 sec)
I0916 22:00:26.860419 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.40029
I0916 22:00:26.862730 139906052065152 basic_session_run_hooks.py:260] loss = 0.14968874, step = 3600 (22.725 sec)
I0916 22:00:49.821266 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.35523
I0916 22:00:49.824218 139906052065152 basic_session_run_hooks.py:260] loss = 3.1817722, step = 3700 (22.961 sec)
I0916 22:01:12.520474 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.40544
I0916 22:01:12.522597 139906052065152 basic_session_run_hooks.py:260] loss = 0.20803973, step = 3800 (22.698 sec)
I0916 22:01:35.149177 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.41917
I0916 22:01:35.152283 139906052065152 basic_session_run_hooks.py:260] loss = 0.14506869, step = 3900 (22.630 sec)
I0916 22:01:57.581938 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 4000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
:::MLPv0.5.0 transformer 1568671319.044713020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:01:59.044744 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671319.044713020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:01:59.045027 139906052065152 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*
I0916 22:01:59.047658 139906052065152 problem.py:644] partition: 0 num_data_files: 1
I0916 22:01:59.287291 139906052065152 estimator.py:1145] Calling model_fn.
:::MLPv0.5.0 transformer 1568671319.730479002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:01:59.730516 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671319.730479002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:01:59.730876 139906052065152 t2t_model.py:1905] Setting T2TModel mode to 'eval'
I0916 22:01:59.731151 139906052065152 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0
I0916 22:01:59.731281 139906052065152 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0
I0916 22:01:59.731399 139906052065152 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0
I0916 22:01:59.731537 139906052065152 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0
I0916 22:01:59.731724 139906052065152 t2t_model.py:1905] Setting hparams.dropout to 0.0
I0916 22:01:59.731898 139906052065152 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0
:::MLPv0.5.0 transformer 1568671319.836707115 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
W0916 22:01:59.855849 139906052065152 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7f3e3316d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.
I0916 22:01:59.839287 139906052065152 api.py:452] :::MLPv0.5.0 transformer 1568671319.836707115 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
I0916 22:01:59.856761 139906052065152 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 22:01:59.953655 139906052065152 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_17594_256.bottom
I0916 22:02:00.139805 139906052065152 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_17594_256.targets_bottom
I0916 22:02:00.166887 139906052065152 t2t_model.py:1905] Building model body
:::MLPv0.5.0 transformer 1568671320.261490107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
I0916 22:02:00.261518 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.261490107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568671320.263334036 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
I0916 22:02:00.263350 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.263334036 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568671320.265089989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
I0916 22:02:00.265122 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.265089989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568671320.266767979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 22:02:00.266782 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.266767979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568671320.562431097 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:02:00.562490 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.562431097 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568671320.564222097 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:02:00.564254 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.564222097 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568671320.566062927 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:02:00.566092 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.566062927 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568671320.961532116 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:02:00.961579 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.961532116 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568671320.963258028 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:02:00.963274 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.963258028 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568671320.964884043 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:02:00.964900 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671320.964884043 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568671321.067662954 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
I0916 22:02:01.067687 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671321.067662954 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
:::MLPv0.5.0 transformer 1568671321.184827089 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
I0916 22:02:01.184875 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671321.184827089 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568671321.188450098 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
I0916 22:02:01.188473 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671321.188450098 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568671321.191648960 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
I0916 22:02:01.191673 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671321.191648960 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568671321.193373919 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 22:02:01.193397 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671321.193373919 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568671322.168581963 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:02:02.168613 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671322.168581963 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568671322.170355082 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:02:02.170372 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671322.170355082 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568671322.171969891 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:02:02.171984 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671322.171969891 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568671322.786227942 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:02:02.786278 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671322.786227942 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568671322.789930105 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:02:02.789968 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671322.789930105 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568671322.792701006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:02:02.792722 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671322.792701006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568671322.877080917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:02:02.877110 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568671322.877080917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:02:02.912283 139906052065152 t2t_model.py:1905] Transforming body output with symbol_modality_17594_256.top
I0916 22:02:03.789278 139906052065152 estimator.py:1147] Done calling model_fn.
I0916 22:02:03.812722 139906052065152 evaluation.py:255] Starting evaluation at 2019-09-16T22:02:03Z
I0916 22:02:04.110846 139906052065152 monitored_session.py:240] Graph was finalized.
2019-09-16 22:02:04.111775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:02:04.112458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-09-16 22:02:04.112611: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 22:02:04.112664: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 22:02:04.112693: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-16 22:02:04.112720: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-16 22:02:04.112742: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-16 22:02:04.112765: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-16 22:02:04.112799: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 22:02:04.112888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:02:04.113613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:02:04.114226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 22:02:04.114277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 22:02:04.114292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 22:02:04.114302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 22:02:04.114428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:02:04.115103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:02:04.115706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
I0916 22:02:04.117449 139906052065152 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-4000
I0916 22:02:04.554641 139906052065152 session_manager.py:500] Running local_init_op.
I0916 22:02:04.638494 139906052065152 session_manager.py:502] Done running local_init_op.
I0916 22:02:08.131103 139906052065152 evaluation.py:167] Evaluation [10/100]
I0916 22:02:10.008667 139906052065152 evaluation.py:167] Evaluation [20/100]
I0916 22:02:11.557693 139906052065152 evaluation.py:275] Finished evaluation at 2019-09-16-22:02:11
I0916 22:02:11.558031 139906052065152 estimator.py:2039] Saving dict for global step 4000: global_step = 4000, loss = 0.24545605, metrics-translate_enasl/targets/accuracy = 0.9762292, metrics-translate_enasl/targets/accuracy_per_sequence = 0.7794621, metrics-translate_enasl/targets/accuracy_top5 = 0.9898462, metrics-translate_enasl/targets/approx_bleu_score = 0.87383235, metrics-translate_enasl/targets/neg_log_perplexity = -0.1849558, metrics-translate_enasl/targets/rouge_2_fscore = 0.8991928, metrics-translate_enasl/targets/rouge_L_fscore = 0.9152902
I0916 22:02:11.558828 139906052065152 estimator.py:2099] Saving 'checkpoint_path' summary for global step 4000: /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-4000
I0916 22:02:11.813930 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 2.72742
I0916 22:02:11.816518 139906052065152 basic_session_run_hooks.py:260] loss = 0.20104416, step = 4000 (36.664 sec)
I0916 22:02:34.400422 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.42741
I0916 22:02:34.403060 139906052065152 basic_session_run_hooks.py:260] loss = 0.14445798, step = 4100 (22.587 sec)
I0916 22:02:56.869498 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.45056
I0916 22:02:56.872498 139906052065152 basic_session_run_hooks.py:260] loss = 0.15732832, step = 4200 (22.469 sec)
I0916 22:03:19.770592 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.36661
I0916 22:03:19.773346 139906052065152 basic_session_run_hooks.py:260] loss = 0.13581218, step = 4300 (22.901 sec)
I0916 22:03:42.594674 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.38134
I0916 22:03:42.597206 139906052065152 basic_session_run_hooks.py:260] loss = 0.46360096, step = 4400 (22.824 sec)
I0916 22:04:05.418055 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.38146
I0916 22:04:05.420692 139906052065152 basic_session_run_hooks.py:260] loss = 0.17898265, step = 4500 (22.823 sec)
I0916 22:04:28.361900 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.35847
I0916 22:04:28.364464 139906052065152 basic_session_run_hooks.py:260] loss = 0.11794729, step = 4600 (22.944 sec)
I0916 22:04:51.350383 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.35
I0916 22:04:51.352760 139906052065152 basic_session_run_hooks.py:260] loss = 0.09860681, step = 4700 (22.988 sec)
I0916 22:05:14.712105 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28051
I0916 22:05:14.714848 139906052065152 basic_session_run_hooks.py:260] loss = 0.14297694, step = 4800 (23.362 sec)
I0916 22:05:37.844114 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.32302
I0916 22:05:37.846265 139906052065152 basic_session_run_hooks.py:260] loss = 0.085352406, step = 4900 (23.131 sec)
I0916 22:06:00.785727 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:06:01.631236 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:06:01.887788 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.15909
I0916 22:06:01.889565 139906052065152 basic_session_run_hooks.py:260] loss = 0.2689661, step = 5000 (24.043 sec)
I0916 22:06:24.668926 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.3896
I0916 22:06:24.670911 139906052065152 basic_session_run_hooks.py:260] loss = 0.14978567, step = 5100 (22.781 sec)
I0916 22:06:47.741293 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.33419
I0916 22:06:47.743747 139906052065152 basic_session_run_hooks.py:260] loss = 0.14757247, step = 5200 (23.073 sec)
I0916 22:07:10.722731 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.35135
I0916 22:07:10.725302 139906052065152 basic_session_run_hooks.py:260] loss = 0.14848757, step = 5300 (22.982 sec)
I0916 22:07:34.096056 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.27837
I0916 22:07:34.098088 139906052065152 basic_session_run_hooks.py:260] loss = 0.11479139, step = 5400 (23.373 sec)
I0916 22:07:56.882848 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.3885
I0916 22:07:56.885135 139906052065152 basic_session_run_hooks.py:260] loss = 0.19584686, step = 5500 (22.787 sec)
I0916 22:08:19.527906 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.41597
I0916 22:08:19.530700 139906052065152 basic_session_run_hooks.py:260] loss = 0.122324675, step = 5600 (22.646 sec)
I0916 22:08:42.089370 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.43234
I0916 22:08:42.091327 139906052065152 basic_session_run_hooks.py:260] loss = 0.1300806, step = 5700 (22.561 sec)
I0916 22:09:05.115405 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.34292
I0916 22:09:05.117789 139906052065152 basic_session_run_hooks.py:260] loss = 0.2349094, step = 5800 (23.026 sec)
I0916 22:09:28.051418 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.35995
I0916 22:09:28.058370 139906052065152 basic_session_run_hooks.py:260] loss = 0.07331097, step = 5900 (22.941 sec)
I0916 22:09:50.450529 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 6000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:09:51.924171 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:09:52.157100 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.14841
I0916 22:09:52.159147 139906052065152 basic_session_run_hooks.py:260] loss = 0.19442166, step = 6000 (24.101 sec)
I0916 22:10:15.207065 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.3384
I0916 22:10:15.209382 139906052065152 basic_session_run_hooks.py:260] loss = 0.1334808, step = 6100 (23.050 sec)
I0916 22:10:38.012464 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.38493
I0916 22:10:38.015121 139906052065152 basic_session_run_hooks.py:260] loss = 0.17847721, step = 6200 (22.806 sec)
I0916 22:11:01.100825 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.3312
I0916 22:11:01.102843 139906052065152 basic_session_run_hooks.py:260] loss = 0.17473286, step = 6300 (23.088 sec)
I0916 22:11:24.071743 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.35333
I0916 22:11:24.074059 139906052065152 basic_session_run_hooks.py:260] loss = 0.11763076, step = 6400 (22.971 sec)
I0916 22:11:47.203305 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.32309
I0916 22:11:47.206284 139906052065152 basic_session_run_hooks.py:260] loss = 0.086451486, step = 6500 (23.132 sec)
I0916 22:12:10.480943 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.29596
I0916 22:12:10.483016 139906052065152 basic_session_run_hooks.py:260] loss = 0.12423902, step = 6600 (23.277 sec)
I0916 22:12:33.951252 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2607
I0916 22:12:33.953197 139906052065152 basic_session_run_hooks.py:260] loss = 0.069251016, step = 6700 (23.470 sec)
I0916 22:12:57.474505 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25112
I0916 22:12:57.477663 139906052065152 basic_session_run_hooks.py:260] loss = 0.20167838, step = 6800 (23.524 sec)
I0916 22:13:20.491727 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.34457
I0916 22:13:20.494209 139906052065152 basic_session_run_hooks.py:260] loss = 0.09188444, step = 6900 (23.017 sec)
I0916 22:13:43.258315 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 7000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
:::MLPv0.5.0 transformer 1568672024.137070894 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:13:44.137103 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672024.137070894 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:13:44.137434 139906052065152 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*
I0916 22:13:44.139050 139906052065152 problem.py:644] partition: 0 num_data_files: 1
I0916 22:13:44.386137 139906052065152 estimator.py:1145] Calling model_fn.
:::MLPv0.5.0 transformer 1568672024.851856947 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:13:44.851897 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672024.851856947 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:13:44.852231 139906052065152 t2t_model.py:1905] Setting T2TModel mode to 'eval'
I0916 22:13:44.852474 139906052065152 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0
I0916 22:13:44.852627 139906052065152 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0
I0916 22:13:44.852749 139906052065152 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0
I0916 22:13:44.852899 139906052065152 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0
I0916 22:13:44.853037 139906052065152 t2t_model.py:1905] Setting hparams.dropout to 0.0
I0916 22:13:44.853152 139906052065152 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0
:::MLPv0.5.0 transformer 1568672024.962124109 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
W0916 22:13:44.982762 139906052065152 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7f3e3316d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.
I0916 22:13:44.964488 139906052065152 api.py:452] :::MLPv0.5.0 transformer 1568672024.962124109 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
I0916 22:13:44.983830 139906052065152 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 22:13:45.080251 139906052065152 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_17594_256.bottom
I0916 22:13:45.264370 139906052065152 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_17594_256.targets_bottom
I0916 22:13:45.292207 139906052065152 t2t_model.py:1905] Building model body
:::MLPv0.5.0 transformer 1568672025.389132023 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
I0916 22:13:45.389161 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672025.389132023 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568672025.390964031 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
I0916 22:13:45.390980 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672025.390964031 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568672025.392468929 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
I0916 22:13:45.392483 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672025.392468929 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568672025.394016981 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 22:13:45.394032 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672025.394016981 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672025.692106009 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:13:45.692136 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672025.692106009 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568672025.693865061 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:13:45.693897 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672025.693865061 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672025.695537090 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:13:45.695564 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672025.695537090 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568672026.506289959 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:13:46.506320 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672026.506289959 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568672026.508181095 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:13:46.508197 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672026.508181095 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672026.509797096 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:13:46.509813 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672026.509797096 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568672026.620120049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
I0916 22:13:46.620142 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672026.620120049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
:::MLPv0.5.0 transformer 1568672026.735260963 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
I0916 22:13:46.735292 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672026.735260963 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568672026.737231016 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
I0916 22:13:46.737246 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672026.737231016 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568672026.739083052 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
I0916 22:13:46.739099 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672026.739083052 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568672026.742189884 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 22:13:46.742212 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672026.742189884 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672027.263606071 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:13:47.263637 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672027.263606071 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568672027.265511990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:13:47.265530 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672027.265511990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672027.267185926 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:13:47.267201 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672027.267185926 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568672027.865720034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:13:47.865750 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672027.865720034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568672027.868158102 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:13:47.868175 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672027.868158102 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672027.869760036 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:13:47.869776 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672027.869760036 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568672027.952181101 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:13:47.952208 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672027.952181101 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:13:47.985028 139906052065152 t2t_model.py:1905] Transforming body output with symbol_modality_17594_256.top
I0916 22:13:48.837665 139906052065152 estimator.py:1147] Done calling model_fn.
I0916 22:13:48.859277 139906052065152 evaluation.py:255] Starting evaluation at 2019-09-16T22:13:48Z
I0916 22:13:49.666481 139906052065152 monitored_session.py:240] Graph was finalized.
2019-09-16 22:13:49.667695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:13:49.668613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-09-16 22:13:49.668749: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 22:13:49.668797: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 22:13:49.668839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-16 22:13:49.668884: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-16 22:13:49.668932: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-16 22:13:49.668975: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-16 22:13:49.669014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 22:13:49.669146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:13:49.670013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:13:49.670817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 22:13:49.670891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 22:13:49.670919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 22:13:49.670938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 22:13:49.671172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:13:49.672000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:13:49.672721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
I0916 22:13:49.675065 139906052065152 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-7000
I0916 22:13:50.103934 139906052065152 session_manager.py:500] Running local_init_op.
I0916 22:13:50.181385 139906052065152 session_manager.py:502] Done running local_init_op.
I0916 22:13:53.845174 139906052065152 evaluation.py:167] Evaluation [10/100]
I0916 22:13:55.823498 139906052065152 evaluation.py:167] Evaluation [20/100]
I0916 22:13:57.424232 139906052065152 evaluation.py:275] Finished evaluation at 2019-09-16-22:13:57
I0916 22:13:57.424598 139906052065152 estimator.py:2039] Saving dict for global step 7000: global_step = 7000, loss = 0.18278465, metrics-translate_enasl/targets/accuracy = 0.983182, metrics-translate_enasl/targets/accuracy_per_sequence = 0.8268949, metrics-translate_enasl/targets/accuracy_top5 = 0.99357194, metrics-translate_enasl/targets/approx_bleu_score = 0.8942776, metrics-translate_enasl/targets/neg_log_perplexity = -0.14781286, metrics-translate_enasl/targets/rouge_2_fscore = 0.9172197, metrics-translate_enasl/targets/rouge_L_fscore = 0.92701095
I0916 22:13:57.425411 139906052065152 estimator.py:2099] Saving 'checkpoint_path' summary for global step 7000: /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-7000
I0916 22:13:57.641366 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 2.69181
I0916 22:13:57.643363 139906052065152 basic_session_run_hooks.py:260] loss = 0.14416344, step = 7000 (37.149 sec)
I0916 22:14:20.704911 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.33586
I0916 22:14:20.707123 139906052065152 basic_session_run_hooks.py:260] loss = 0.12893082, step = 7100 (23.064 sec)
I0916 22:14:43.874134 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.31609
I0916 22:14:43.876600 139906052065152 basic_session_run_hooks.py:260] loss = 0.2003324, step = 7200 (23.169 sec)
I0916 22:15:07.026388 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.31922
I0916 22:15:07.029244 139906052065152 basic_session_run_hooks.py:260] loss = 0.16859993, step = 7300 (23.153 sec)
I0916 22:15:30.315851 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.29379
I0916 22:15:30.317996 139906052065152 basic_session_run_hooks.py:260] loss = 0.12275684, step = 7400 (23.289 sec)
I0916 22:15:53.364834 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.33859
I0916 22:15:53.367722 139906052065152 basic_session_run_hooks.py:260] loss = 0.12303732, step = 7500 (23.050 sec)
I0916 22:16:16.840174 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25979
I0916 22:16:16.842982 139906052065152 basic_session_run_hooks.py:260] loss = 0.33781144, step = 7600 (23.475 sec)
I0916 22:16:40.186839 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28327
I0916 22:16:40.189246 139906052065152 basic_session_run_hooks.py:260] loss = 0.07700779, step = 7700 (23.346 sec)
I0916 22:17:03.368973 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.31366
I0916 22:17:03.371021 139906052065152 basic_session_run_hooks.py:260] loss = 0.09347771, step = 7800 (23.182 sec)
I0916 22:17:27.112620 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21165
I0916 22:17:27.115422 139906052065152 basic_session_run_hooks.py:260] loss = 0.08417759, step = 7900 (23.744 sec)
I0916 22:17:50.967706 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 8000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:17:51.843449 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:17:52.109209 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.00055
I0916 22:17:52.111352 139906052065152 basic_session_run_hooks.py:260] loss = 0.11598629, step = 8000 (24.996 sec)
I0916 22:18:15.406033 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.29244
I0916 22:18:15.408365 139906052065152 basic_session_run_hooks.py:260] loss = 0.105164915, step = 8100 (23.297 sec)
I0916 22:18:38.671525 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2982
I0916 22:18:38.673883 139906052065152 basic_session_run_hooks.py:260] loss = 0.16587181, step = 8200 (23.266 sec)
I0916 22:19:02.199101 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25033
I0916 22:19:02.201617 139906052065152 basic_session_run_hooks.py:260] loss = 0.08400998, step = 8300 (23.528 sec)
I0916 22:19:25.892011 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.22068
I0916 22:19:25.894373 139906052065152 basic_session_run_hooks.py:260] loss = 0.105476506, step = 8400 (23.693 sec)
I0916 22:19:49.937439 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.15879
I0916 22:19:49.940213 139906052065152 basic_session_run_hooks.py:260] loss = 0.10202606, step = 8500 (24.046 sec)
I0916 22:20:14.225800 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.1172
I0916 22:20:14.229368 139906052065152 basic_session_run_hooks.py:260] loss = 0.12958375, step = 8600 (24.289 sec)
I0916 22:20:37.945138 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21596
I0916 22:20:37.947397 139906052065152 basic_session_run_hooks.py:260] loss = 0.114759944, step = 8700 (23.718 sec)
I0916 22:21:01.839251 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.18513
I0916 22:21:01.842081 139906052065152 basic_session_run_hooks.py:260] loss = 0.17207578, step = 8800 (23.895 sec)
I0916 22:21:26.024502 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.13477
I0916 22:21:26.032305 139906052065152 basic_session_run_hooks.py:260] loss = 0.15297408, step = 8900 (24.190 sec)
I0916 22:21:49.912396 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 9000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:21:50.827019 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:21:51.094722 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 3.98878
I0916 22:21:51.096633 139906052065152 basic_session_run_hooks.py:260] loss = 0.06349233, step = 9000 (25.064 sec)
I0916 22:22:14.427635 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2858
I0916 22:22:14.429586 139906052065152 basic_session_run_hooks.py:260] loss = 0.07172137, step = 9100 (23.333 sec)
I0916 22:22:37.990191 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24401
I0916 22:22:37.992013 139906052065152 basic_session_run_hooks.py:260] loss = 0.082885385, step = 9200 (23.562 sec)
I0916 22:23:01.747162 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.20929
I0916 22:23:01.750085 139906052065152 basic_session_run_hooks.py:260] loss = 0.20916602, step = 9300 (23.758 sec)
I0916 22:23:25.093756 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28328
I0916 22:23:25.096226 139906052065152 basic_session_run_hooks.py:260] loss = 0.077578254, step = 9400 (23.346 sec)
I0916 22:23:48.807729 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21692
I0916 22:23:48.810395 139906052065152 basic_session_run_hooks.py:260] loss = 0.06469907, step = 9500 (23.714 sec)
I0916 22:24:12.767733 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.17363
I0916 22:24:12.770339 139906052065152 basic_session_run_hooks.py:260] loss = 0.06706605, step = 9600 (23.960 sec)
I0916 22:24:36.495012 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21457
I0916 22:24:36.499466 139906052065152 basic_session_run_hooks.py:260] loss = 0.08548979, step = 9700 (23.729 sec)
I0916 22:25:00.130521 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2309
I0916 22:25:00.133384 139906052065152 basic_session_run_hooks.py:260] loss = 0.0791777, step = 9800 (23.634 sec)
I0916 22:25:23.794090 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.22591
I0916 22:25:23.796567 139906052065152 basic_session_run_hooks.py:260] loss = 0.09595898, step = 9900 (23.663 sec)
I0916 22:25:47.392086 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
:::MLPv0.5.0 transformer 1568672748.298392057 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:25:48.298424 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672748.298392057 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:25:48.298760 139906052065152 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*
I0916 22:25:48.300528 139906052065152 problem.py:644] partition: 0 num_data_files: 1
I0916 22:25:48.536847 139906052065152 estimator.py:1145] Calling model_fn.
:::MLPv0.5.0 transformer 1568672748.971843004 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:25:48.971882 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672748.971843004 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:25:48.972244 139906052065152 t2t_model.py:1905] Setting T2TModel mode to 'eval'
I0916 22:25:48.972465 139906052065152 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0
I0916 22:25:48.972625 139906052065152 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0
I0916 22:25:48.972733 139906052065152 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0
I0916 22:25:48.972826 139906052065152 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0
I0916 22:25:48.972910 139906052065152 t2t_model.py:1905] Setting hparams.dropout to 0.0
I0916 22:25:48.972995 139906052065152 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0
:::MLPv0.5.0 transformer 1568672749.076971054 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
W0916 22:25:49.099509 139906052065152 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7f3e3316d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.
I0916 22:25:49.079498 139906052065152 api.py:452] :::MLPv0.5.0 transformer 1568672749.076971054 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
I0916 22:25:49.100754 139906052065152 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 22:25:49.201229 139906052065152 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_17594_256.bottom
I0916 22:25:49.397290 139906052065152 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_17594_256.targets_bottom
I0916 22:25:49.427622 139906052065152 t2t_model.py:1905] Building model body
:::MLPv0.5.0 transformer 1568672749.527936935 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
I0916 22:25:49.527975 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672749.527936935 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568672749.529901981 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
I0916 22:25:49.529920 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672749.529901981 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568672749.531446934 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
I0916 22:25:49.531462 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672749.531446934 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568672749.532967091 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 22:25:49.532982 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672749.532967091 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672749.839905977 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:25:49.839942 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672749.839905977 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568672749.841656923 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:25:49.841674 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672749.841656923 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672749.843162060 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:25:49.843178 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672749.843162060 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568672750.888812065 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:25:50.888854 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672750.888812065 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568672750.890667915 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:25:50.890691 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672750.890667915 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672750.892261982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:25:50.892290 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672750.892261982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568672751.010092020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
I0916 22:25:51.010130 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672751.010092020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
:::MLPv0.5.0 transformer 1568672751.739787102 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:25:51.739836 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672751.739787102 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568672751.741550922 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:25:51.741573 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672751.741550922 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672751.743133068 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:25:51.743149 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672751.743133068 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568672752.404318094 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:25:52.404365 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672752.404318094 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568672752.406101942 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:25:52.406121 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672752.406101942 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568672752.407711983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:25:52.407727 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672752.407711983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568672752.508330107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:25:52.508377 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568672752.508330107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:25:52.545250 139906052065152 t2t_model.py:1905] Transforming body output with symbol_modality_17594_256.top
I0916 22:25:53.425947 139906052065152 estimator.py:1147] Done calling model_fn.
I0916 22:25:53.448581 139906052065152 evaluation.py:255] Starting evaluation at 2019-09-16T22:25:53Z
I0916 22:25:54.232462 139906052065152 monitored_session.py:240] Graph was finalized.
2019-09-16 22:25:54.233679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:25:54.234380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-09-16 22:25:54.234488: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 22:25:54.234518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 22:25:54.234568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-16 22:25:54.234613: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-16 22:25:54.234653: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-16 22:25:54.234676: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-16 22:25:54.234700: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 22:25:54.234787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:25:54.235438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:25:54.236027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 22:25:54.236080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 22:25:54.236095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 22:25:54.236106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 22:25:54.236246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:25:54.236916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:25:54.237513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
I0916 22:25:54.239329 139906052065152 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-10000
I0916 22:25:54.789701 139906052065152 session_manager.py:500] Running local_init_op.
I0916 22:25:54.909925 139906052065152 session_manager.py:502] Done running local_init_op.
I0916 22:25:58.868938 139906052065152 evaluation.py:167] Evaluation [10/100]
I0916 22:26:00.714101 139906052065152 evaluation.py:167] Evaluation [20/100]
I0916 22:26:02.437014 139906052065152 evaluation.py:275] Finished evaluation at 2019-09-16-22:26:02
I0916 22:26:02.437436 139906052065152 estimator.py:2039] Saving dict for global step 10000: global_step = 10000, loss = 0.15153022, metrics-translate_enasl/targets/accuracy = 0.98667157, metrics-translate_enasl/targets/accuracy_per_sequence = 0.85281175, metrics-translate_enasl/targets/accuracy_top5 = 0.99569714, metrics-translate_enasl/targets/approx_bleu_score = 0.90427977, metrics-translate_enasl/targets/neg_log_perplexity = -0.12659138, metrics-translate_enasl/targets/rouge_2_fscore = 0.92619294, metrics-translate_enasl/targets/rouge_L_fscore = 0.9315778
I0916 22:26:02.438316 139906052065152 estimator.py:2099] Saving 'checkpoint_path' summary for global step 10000: /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-10000
I0916 22:26:02.672103 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 2.57215
I0916 22:26:02.677057 139906052065152 basic_session_run_hooks.py:260] loss = 0.075433895, step = 10000 (38.880 sec)
I0916 22:26:26.470350 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.20198
I0916 22:26:26.473201 139906052065152 basic_session_run_hooks.py:260] loss = 0.075912364, step = 10100 (23.796 sec)
I0916 22:26:50.578192 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.14805
I0916 22:26:50.582084 139906052065152 basic_session_run_hooks.py:260] loss = 0.050062552, step = 10200 (24.109 sec)
I0916 22:27:14.966908 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.10025
I0916 22:27:14.968918 139906052065152 basic_session_run_hooks.py:260] loss = 0.08628113, step = 10300 (24.387 sec)
I0916 22:27:38.854578 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.18627
I0916 22:27:38.857009 139906052065152 basic_session_run_hooks.py:260] loss = 0.08063294, step = 10400 (23.888 sec)
I0916 22:28:02.800281 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.1761
I0916 22:28:02.803334 139906052065152 basic_session_run_hooks.py:260] loss = 0.048976794, step = 10500 (23.946 sec)
I0916 22:28:26.584611 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.20446
I0916 22:28:26.586987 139906052065152 basic_session_run_hooks.py:260] loss = 0.27367085, step = 10600 (23.784 sec)
I0916 22:28:50.091036 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25422
I0916 22:28:50.093432 139906052065152 basic_session_run_hooks.py:260] loss = 0.17205161, step = 10700 (23.506 sec)
I0916 22:29:13.986515 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.18482
I0916 22:29:13.988238 139906052065152 basic_session_run_hooks.py:260] loss = 0.07175402, step = 10800 (23.895 sec)
I0916 22:29:37.860394 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.18869
I0916 22:29:37.862456 139906052065152 basic_session_run_hooks.py:260] loss = 0.19041929, step = 10900 (23.874 sec)
I0916 22:30:01.468300 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 11000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:30:02.364449 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:30:02.620382 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.03877
I0916 22:30:02.622293 139906052065152 basic_session_run_hooks.py:260] loss = 0.070225075, step = 11000 (24.760 sec)
I0916 22:30:26.174407 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24556
I0916 22:30:26.176688 139906052065152 basic_session_run_hooks.py:260] loss = 0.23473442, step = 11100 (23.554 sec)
I0916 22:30:49.936871 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.20832
I0916 22:30:49.938985 139906052065152 basic_session_run_hooks.py:260] loss = 0.05314351, step = 11200 (23.762 sec)
I0916 22:31:13.294992 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28117
I0916 22:31:13.297485 139906052065152 basic_session_run_hooks.py:260] loss = 0.08593357, step = 11300 (23.359 sec)
I0916 22:31:36.936515 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.22984
I0916 22:31:36.938436 139906052065152 basic_session_run_hooks.py:260] loss = 0.058085855, step = 11400 (23.641 sec)
I0916 22:32:00.293004 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28146
I0916 22:32:00.294697 139906052065152 basic_session_run_hooks.py:260] loss = 0.037587386, step = 11500 (23.356 sec)
I0916 22:32:23.844106 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2461
I0916 22:32:23.846681 139906052065152 basic_session_run_hooks.py:260] loss = 0.057257246, step = 11600 (23.552 sec)
I0916 22:32:48.065300 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.12861
I0916 22:32:48.068428 139906052065152 basic_session_run_hooks.py:260] loss = 0.0411523, step = 11700 (24.222 sec)
I0916 22:33:11.963402 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.18443
I0916 22:33:11.965682 139906052065152 basic_session_run_hooks.py:260] loss = 0.08743486, step = 11800 (23.897 sec)
I0916 22:33:36.554019 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.06659
I0916 22:33:36.556577 139906052065152 basic_session_run_hooks.py:260] loss = 0.062201343, step = 11900 (24.591 sec)
I0916 22:34:00.013020 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 12000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:34:00.925326 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:34:01.181164 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.06056
I0916 22:34:01.182775 139906052065152 basic_session_run_hooks.py:260] loss = 0.061967887, step = 12000 (24.626 sec)
I0916 22:34:25.172461 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.16818
I0916 22:34:25.175041 139906052065152 basic_session_run_hooks.py:260] loss = 0.10378462, step = 12100 (23.992 sec)
I0916 22:34:49.105531 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.17832
I0916 22:34:49.108311 139906052065152 basic_session_run_hooks.py:260] loss = 0.066618, step = 12200 (23.933 sec)
I0916 22:35:12.439059 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28567
I0916 22:35:12.441989 139906052065152 basic_session_run_hooks.py:260] loss = 0.045828238, step = 12300 (23.334 sec)
I0916 22:35:35.536664 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.32947
I0916 22:35:35.540662 139906052065152 basic_session_run_hooks.py:260] loss = 0.064191796, step = 12400 (23.099 sec)
I0916 22:35:59.252770 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21654
I0916 22:35:59.255259 139906052065152 basic_session_run_hooks.py:260] loss = 0.051180568, step = 12500 (23.715 sec)
I0916 22:36:22.489964 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.30344
I0916 22:36:22.493084 139906052065152 basic_session_run_hooks.py:260] loss = 0.052528746, step = 12600 (23.238 sec)
I0916 22:36:45.588339 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.3293
I0916 22:36:45.590823 139906052065152 basic_session_run_hooks.py:260] loss = 0.062541984, step = 12700 (23.098 sec)
I0916 22:37:08.843477 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.30013
I0916 22:37:08.847059 139906052065152 basic_session_run_hooks.py:260] loss = 0.081133746, step = 12800 (23.256 sec)
I0916 22:37:31.957520 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.32637
I0916 22:37:31.959820 139906052065152 basic_session_run_hooks.py:260] loss = 0.06794393, step = 12900 (23.113 sec)
I0916 22:37:55.076308 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 13000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
:::MLPv0.5.0 transformer 1568673475.943003893 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:37:55.943037 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673475.943003893 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:37:55.943322 139906052065152 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*
I0916 22:37:55.944839 139906052065152 problem.py:644] partition: 0 num_data_files: 1
I0916 22:37:56.162628 139906052065152 estimator.py:1145] Calling model_fn.
:::MLPv0.5.0 transformer 1568673476.597287893 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:37:56.597326 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673476.597287893 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:37:56.597676 139906052065152 t2t_model.py:1905] Setting T2TModel mode to 'eval'
I0916 22:37:56.597923 139906052065152 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0
I0916 22:37:56.598069 139906052065152 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0
I0916 22:37:56.598212 139906052065152 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0
I0916 22:37:56.598335 139906052065152 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0
I0916 22:37:56.598458 139906052065152 t2t_model.py:1905] Setting hparams.dropout to 0.0
I0916 22:37:56.598598 139906052065152 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0
:::MLPv0.5.0 transformer 1568673476.697005987 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
W0916 22:37:56.717830 139906052065152 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7f3e3316d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.
I0916 22:37:56.699351 139906052065152 api.py:452] :::MLPv0.5.0 transformer 1568673476.697005987 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
I0916 22:37:56.718802 139906052065152 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 22:37:56.853275 139906052065152 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_17594_256.bottom
I0916 22:37:57.041383 139906052065152 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_17594_256.targets_bottom
I0916 22:37:57.067327 139906052065152 t2t_model.py:1905] Building model body
:::MLPv0.5.0 transformer 1568673477.163835049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
I0916 22:37:57.163871 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673477.163835049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568673477.165760994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
I0916 22:37:57.165776 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673477.165760994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568673477.167294979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
I0916 22:37:57.167311 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673477.167294979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568673477.168914080 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 22:37:57.168930 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673477.168914080 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568673477.454401970 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:37:57.454437 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673477.454401970 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568673477.456074953 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:37:57.456090 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673477.456074953 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568673477.457587004 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:37:57.457602 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673477.457587004 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568673478.457624912 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:37:58.457657 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673478.457624912 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568673478.459332943 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:37:58.459350 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673478.459332943 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568673478.460931063 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:37:58.460947 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673478.460931063 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568673478.568856955 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
I0916 22:37:58.568876 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673478.568856955 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
:::MLPv0.5.0 transformer 1568673478.686470032 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
I0916 22:37:58.686501 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673478.686470032 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568673478.688438892 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
I0916 22:37:58.688469 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673478.688438892 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568673478.690088034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
I0916 22:37:58.690104 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673478.690088034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568673478.691632032 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 22:37:58.691647 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673478.691632032 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568673479.237646103 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:37:59.237678 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673479.237646103 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568673479.239336967 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:37:59.239352 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673479.239336967 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568673479.241153002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:37:59.241169 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673479.241153002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568673479.837116003 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:37:59.837147 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673479.837116003 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568673479.838922977 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:37:59.838941 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673479.838922977 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568673479.840843916 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:37:59.840861 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673479.840843916 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568673479.932262897 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:37:59.932292 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568673479.932262897 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:37:59.965658 139906052065152 t2t_model.py:1905] Transforming body output with symbol_modality_17594_256.top
I0916 22:38:00.798119 139906052065152 estimator.py:1147] Done calling model_fn.
I0916 22:38:00.819500 139906052065152 evaluation.py:255] Starting evaluation at 2019-09-16T22:38:00Z
I0916 22:38:01.618071 139906052065152 monitored_session.py:240] Graph was finalized.
2019-09-16 22:38:01.619119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:38:01.619936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-09-16 22:38:01.620065: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 22:38:01.620110: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 22:38:01.620168: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-16 22:38:01.620210: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-16 22:38:01.620248: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-16 22:38:01.620289: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-16 22:38:01.620332: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 22:38:01.620456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:38:01.621159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:38:01.621783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 22:38:01.621841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 22:38:01.621864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 22:38:01.621878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 22:38:01.622029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:38:01.622706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:38:01.623346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
I0916 22:38:01.624983 139906052065152 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-13000
I0916 22:38:02.134757 139906052065152 session_manager.py:500] Running local_init_op.
I0916 22:38:02.221084 139906052065152 session_manager.py:502] Done running local_init_op.
I0916 22:38:05.874095 139906052065152 evaluation.py:167] Evaluation [10/100]
I0916 22:38:07.736246 139906052065152 evaluation.py:167] Evaluation [20/100]
I0916 22:38:09.442270 139906052065152 evaluation.py:275] Finished evaluation at 2019-09-16-22:38:09
I0916 22:38:09.442696 139906052065152 estimator.py:2039] Saving dict for global step 13000: global_step = 13000, loss = 0.12696643, metrics-translate_enasl/targets/accuracy = 0.9894002, metrics-translate_enasl/targets/accuracy_per_sequence = 0.8811736, metrics-translate_enasl/targets/accuracy_top5 = 0.99666786, metrics-translate_enasl/targets/approx_bleu_score = 0.912437, metrics-translate_enasl/targets/neg_log_perplexity = -0.112776816, metrics-translate_enasl/targets/rouge_2_fscore = 0.932406, metrics-translate_enasl/targets/rouge_L_fscore = 0.93505704
I0916 22:38:09.443484 139906052065152 estimator.py:2099] Saving 'checkpoint_path' summary for global step 13000: /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-13000
I0916 22:38:09.647228 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 2.65324
I0916 22:38:09.649018 139906052065152 basic_session_run_hooks.py:260] loss = 0.03856272, step = 13000 (37.689 sec)
I0916 22:38:33.187813 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.248
I0916 22:38:33.189862 139906052065152 basic_session_run_hooks.py:260] loss = 0.07966069, step = 13100 (23.541 sec)
I0916 22:38:56.594299 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.27231
I0916 22:38:56.597101 139906052065152 basic_session_run_hooks.py:260] loss = 0.12828283, step = 13200 (23.407 sec)
I0916 22:39:19.718936 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.32439
I0916 22:39:19.721081 139906052065152 basic_session_run_hooks.py:260] loss = 0.054610033, step = 13300 (23.124 sec)
I0916 22:39:42.984173 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.29828
I0916 22:39:42.987154 139906052065152 basic_session_run_hooks.py:260] loss = 0.038473446, step = 13400 (23.266 sec)
I0916 22:40:06.685264 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2192
I0916 22:40:06.687830 139906052065152 basic_session_run_hooks.py:260] loss = 0.04746837, step = 13500 (23.701 sec)
I0916 22:40:30.135142 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.26442
I0916 22:40:30.138247 139906052065152 basic_session_run_hooks.py:260] loss = 0.0740335, step = 13600 (23.450 sec)
I0916 22:40:54.254626 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.14602
I0916 22:40:54.257035 139906052065152 basic_session_run_hooks.py:260] loss = 0.06269213, step = 13700 (24.119 sec)
I0916 22:41:17.613455 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28104
I0916 22:41:17.616061 139906052065152 basic_session_run_hooks.py:260] loss = 0.04970224, step = 13800 (23.359 sec)
I0916 22:41:41.179069 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24347
I0916 22:41:41.181700 139906052065152 basic_session_run_hooks.py:260] loss = 0.04801142, step = 13900 (23.566 sec)
I0916 22:42:04.765346 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 14000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:42:05.662424 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:42:05.911916 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.04322
I0916 22:42:05.913882 139906052065152 basic_session_run_hooks.py:260] loss = 0.033430506, step = 14000 (24.732 sec)
I0916 22:42:29.542392 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23181
I0916 22:42:29.544718 139906052065152 basic_session_run_hooks.py:260] loss = 0.048782866, step = 14100 (23.631 sec)
I0916 22:42:52.965001 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.26939
I0916 22:42:52.973815 139906052065152 basic_session_run_hooks.py:260] loss = 0.055347525, step = 14200 (23.429 sec)
I0916 22:43:17.005331 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.15967
I0916 22:43:17.007530 139906052065152 basic_session_run_hooks.py:260] loss = 0.05300006, step = 14300 (24.034 sec)
I0916 22:43:40.621962 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2343
I0916 22:43:40.624376 139906052065152 basic_session_run_hooks.py:260] loss = 0.03772367, step = 14400 (23.617 sec)
I0916 22:44:04.345427 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21523
I0916 22:44:04.348135 139906052065152 basic_session_run_hooks.py:260] loss = 0.050914086, step = 14500 (23.724 sec)
I0916 22:44:28.294168 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.17559
I0916 22:44:28.296641 139906052065152 basic_session_run_hooks.py:260] loss = 0.044071402, step = 14600 (23.949 sec)
I0916 22:44:51.889018 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23821
I0916 22:44:51.891621 139906052065152 basic_session_run_hooks.py:260] loss = 0.035060838, step = 14700 (23.595 sec)
I0916 22:45:15.861218 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.1715
I0916 22:45:15.863903 139906052065152 basic_session_run_hooks.py:260] loss = 0.04922935, step = 14800 (23.972 sec)
I0916 22:45:39.730207 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.18953
I0916 22:45:39.732398 139906052065152 basic_session_run_hooks.py:260] loss = 0.047512617, step = 14900 (23.868 sec)
I0916 22:46:03.164861 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 15000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:46:04.066129 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:46:04.287251 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.07215
I0916 22:46:04.290158 139906052065152 basic_session_run_hooks.py:260] loss = 0.03934719, step = 15000 (24.558 sec)
I0916 22:46:27.651316 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28008
I0916 22:46:27.653445 139906052065152 basic_session_run_hooks.py:260] loss = 0.030874562, step = 15100 (23.363 sec)
I0916 22:46:51.468221 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.19869
I0916 22:46:51.470309 139906052065152 basic_session_run_hooks.py:260] loss = 0.071535595, step = 15200 (23.817 sec)
I0916 22:47:15.304255 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.19533
I0916 22:47:15.307210 139906052065152 basic_session_run_hooks.py:260] loss = 0.036112837, step = 15300 (23.837 sec)
I0916 22:47:38.938277 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23118
I0916 22:47:38.942531 139906052065152 basic_session_run_hooks.py:260] loss = 0.07966015, step = 15400 (23.634 sec)
I0916 22:48:02.295948 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28125
I0916 22:48:02.298497 139906052065152 basic_session_run_hooks.py:260] loss = 0.039641704, step = 15500 (23.357 sec)
I0916 22:48:25.915018 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23386
I0916 22:48:25.917505 139906052065152 basic_session_run_hooks.py:260] loss = 0.040108528, step = 15600 (23.619 sec)
I0916 22:48:49.123979 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.30869
I0916 22:48:49.126938 139906052065152 basic_session_run_hooks.py:260] loss = 0.047892097, step = 15700 (23.209 sec)
I0916 22:49:12.940455 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.19877
I0916 22:49:12.942729 139906052065152 basic_session_run_hooks.py:260] loss = 0.046765584, step = 15800 (23.816 sec)
I0916 22:49:36.181020 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.30282
I0916 22:49:36.183535 139906052065152 basic_session_run_hooks.py:260] loss = 0.045445822, step = 15900 (23.241 sec)
I0916 22:49:59.213112 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 16000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
:::MLPv0.5.0 transformer 1568674200.093193054 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:50:00.093225 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674200.093193054 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 22:50:00.093561 139906052065152 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*
I0916 22:50:00.095318 139906052065152 problem.py:644] partition: 0 num_data_files: 1
I0916 22:50:00.316178 139906052065152 estimator.py:1145] Calling model_fn.
:::MLPv0.5.0 transformer 1568674200.751252890 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:50:00.751290 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674200.751252890 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 22:50:00.751619 139906052065152 t2t_model.py:1905] Setting T2TModel mode to 'eval'
I0916 22:50:00.751835 139906052065152 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0
I0916 22:50:00.751945 139906052065152 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0
I0916 22:50:00.752037 139906052065152 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0
I0916 22:50:00.752126 139906052065152 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0
I0916 22:50:00.752207 139906052065152 t2t_model.py:1905] Setting hparams.dropout to 0.0
I0916 22:50:00.752290 139906052065152 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0
:::MLPv0.5.0 transformer 1568674200.862687111 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
W0916 22:50:00.882715 139906052065152 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7f3e3316d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.
I0916 22:50:00.865318 139906052065152 api.py:452] :::MLPv0.5.0 transformer 1568674200.862687111 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
I0916 22:50:00.883743 139906052065152 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 22:50:00.982233 139906052065152 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_17594_256.bottom
I0916 22:50:01.172143 139906052065152 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_17594_256.targets_bottom
I0916 22:50:01.199790 139906052065152 t2t_model.py:1905] Building model body
:::MLPv0.5.0 transformer 1568674201.296964884 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
I0916 22:50:01.297014 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674201.296964884 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568674201.298856020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
I0916 22:50:01.298871 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674201.298856020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568674201.300376892 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
I0916 22:50:01.300393 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674201.300376892 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568674201.301888943 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 22:50:01.301903 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674201.301888943 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674201.589931011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:50:01.589962 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674201.589931011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568674201.591622114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:50:01.591639 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674201.591622114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674201.593135118 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:50:01.593149 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674201.593135118 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568674202.603826046 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:50:02.603857 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674202.603826046 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568674202.605498075 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:50:02.605514 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674202.605498075 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674202.607043982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 22:50:02.607059 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674202.607043982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568674202.716279984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
I0916 22:50:02.716315 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674202.716279984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
:::MLPv0.5.0 transformer 1568674202.834475040 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
I0916 22:50:02.834507 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674202.834475040 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568674202.836343050 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
I0916 22:50:02.836359 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674202.836343050 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568674202.838253021 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
I0916 22:50:02.838277 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674202.838253021 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568674202.841279984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 22:50:02.841300 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674202.841279984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674203.388442993 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:50:03.388474 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674203.388442993 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568674203.390156984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:50:03.390178 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674203.390156984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674203.391798973 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:50:03.391813 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674203.391798973 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568674203.994111061 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 22:50:03.994142 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674203.994111061 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568674203.995843887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 22:50:03.995860 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674203.995843887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674203.997354984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 22:50:03.997369 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674203.997354984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568674204.078583002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:50:04.078604 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674204.078583002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 22:50:04.113245 139906052065152 t2t_model.py:1905] Transforming body output with symbol_modality_17594_256.top
I0916 22:50:04.996880 139906052065152 estimator.py:1147] Done calling model_fn.
I0916 22:50:05.017672 139906052065152 evaluation.py:255] Starting evaluation at 2019-09-16T22:50:05Z
I0916 22:50:05.797101 139906052065152 monitored_session.py:240] Graph was finalized.
2019-09-16 22:50:05.798535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:50:05.799302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-09-16 22:50:05.799440: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 22:50:05.799491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 22:50:05.799533: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-16 22:50:05.799596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-16 22:50:05.799643: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-16 22:50:05.799731: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-16 22:50:05.799772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 22:50:05.799899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:50:05.800865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:50:05.801571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 22:50:05.801653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 22:50:05.801675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 22:50:05.801689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 22:50:05.801856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:50:05.802628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 22:50:05.803241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
I0916 22:50:05.805064 139906052065152 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-16000
I0916 22:50:06.259141 139906052065152 session_manager.py:500] Running local_init_op.
I0916 22:50:06.345098 139906052065152 session_manager.py:502] Done running local_init_op.
I0916 22:50:10.041125 139906052065152 evaluation.py:167] Evaluation [10/100]
I0916 22:50:11.927670 139906052065152 evaluation.py:167] Evaluation [20/100]
I0916 22:50:13.574471 139906052065152 evaluation.py:275] Finished evaluation at 2019-09-16-22:50:13
I0916 22:50:13.574919 139906052065152 estimator.py:2039] Saving dict for global step 16000: global_step = 16000, loss = 0.15445341, metrics-translate_enasl/targets/accuracy = 0.98677653, metrics-translate_enasl/targets/accuracy_per_sequence = 0.85085577, metrics-translate_enasl/targets/accuracy_top5 = 0.99522483, metrics-translate_enasl/targets/approx_bleu_score = 0.9060178, metrics-translate_enasl/targets/neg_log_perplexity = -0.13440871, metrics-translate_enasl/targets/rouge_2_fscore = 0.92731047, metrics-translate_enasl/targets/rouge_L_fscore = 0.9322379
I0916 22:50:13.575745 139906052065152 estimator.py:2099] Saving 'checkpoint_path' summary for global step 16000: /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-16000
I0916 22:50:13.810861 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 2.65746
I0916 22:50:13.813839 139906052065152 basic_session_run_hooks.py:260] loss = 0.09204227, step = 16000 (37.630 sec)
I0916 22:50:37.290716 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25897
I0916 22:50:37.292884 139906052065152 basic_session_run_hooks.py:260] loss = 0.06343369, step = 16100 (23.479 sec)
I0916 22:51:00.656013 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.27985
I0916 22:51:00.659013 139906052065152 basic_session_run_hooks.py:260] loss = 0.058816515, step = 16200 (23.366 sec)
I0916 22:51:24.188432 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24946
I0916 22:51:24.191168 139906052065152 basic_session_run_hooks.py:260] loss = 0.04142852, step = 16300 (23.532 sec)
I0916 22:51:47.789288 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23713
I0916 22:51:47.791877 139906052065152 basic_session_run_hooks.py:260] loss = 0.047684148, step = 16400 (23.601 sec)
I0916 22:52:11.511418 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21548
I0916 22:52:11.514182 139906052065152 basic_session_run_hooks.py:260] loss = 0.040057372, step = 16500 (23.722 sec)
I0916 22:52:35.123852 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23505
I0916 22:52:35.125724 139906052065152 basic_session_run_hooks.py:260] loss = 0.046762582, step = 16600 (23.612 sec)
I0916 22:52:58.876007 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21015
I0916 22:52:58.882111 139906052065152 basic_session_run_hooks.py:260] loss = 0.04469158, step = 16700 (23.756 sec)
I0916 22:53:22.244620 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.27926
I0916 22:53:22.248446 139906052065152 basic_session_run_hooks.py:260] loss = 0.05087984, step = 16800 (23.366 sec)
I0916 22:53:45.707602 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.26201
I0916 22:53:45.709852 139906052065152 basic_session_run_hooks.py:260] loss = 0.034938037, step = 16900 (23.461 sec)
I0916 22:54:09.088084 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 17000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:54:09.991266 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:54:10.227962 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.07825
I0916 22:54:10.230329 139906052065152 basic_session_run_hooks.py:260] loss = 0.038334515, step = 17000 (24.520 sec)
I0916 22:54:33.878915 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.22815
I0916 22:54:33.881227 139906052065152 basic_session_run_hooks.py:260] loss = 0.035161987, step = 17100 (23.651 sec)
I0916 22:54:58.017515 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.14275
I0916 22:54:58.020189 139906052065152 basic_session_run_hooks.py:260] loss = 0.062903896, step = 17200 (24.139 sec)
I0916 22:55:21.484985 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.26122
I0916 22:55:21.487483 139906052065152 basic_session_run_hooks.py:260] loss = 0.045856364, step = 17300 (23.467 sec)
I0916 22:55:44.814903 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28634
I0916 22:55:44.816903 139906052065152 basic_session_run_hooks.py:260] loss = 0.04139575, step = 17400 (23.329 sec)
I0916 22:56:08.426084 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23529
I0916 22:56:08.430704 139906052065152 basic_session_run_hooks.py:260] loss = 0.034381963, step = 17500 (23.614 sec)
I0916 22:56:31.755069 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28651
I0916 22:56:31.757040 139906052065152 basic_session_run_hooks.py:260] loss = 0.05130182, step = 17600 (23.326 sec)
I0916 22:56:55.307085 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24592
I0916 22:56:55.308981 139906052065152 basic_session_run_hooks.py:260] loss = 0.045245185, step = 17700 (23.552 sec)
I0916 22:57:19.012157 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21851
I0916 22:57:19.014662 139906052065152 basic_session_run_hooks.py:260] loss = 0.055079438, step = 17800 (23.706 sec)
I0916 22:57:42.506992 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25625
I0916 22:57:42.509181 139906052065152 basic_session_run_hooks.py:260] loss = 0.040457614, step = 17900 (23.495 sec)
I0916 22:58:05.287527 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 18000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 22:58:06.202136 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 22:58:06.447940 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.17694
I0916 22:58:06.449852 139906052065152 basic_session_run_hooks.py:260] loss = 0.041654047, step = 18000 (23.941 sec)
I0916 22:58:29.968254 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25164
I0916 22:58:29.970859 139906052065152 basic_session_run_hooks.py:260] loss = 0.04618604, step = 18100 (23.521 sec)
I0916 22:58:53.411119 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.26569
I0916 22:58:53.413777 139906052065152 basic_session_run_hooks.py:260] loss = 0.04363783, step = 18200 (23.443 sec)
I0916 22:59:17.481220 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.15454
I0916 22:59:17.483954 139906052065152 basic_session_run_hooks.py:260] loss = 0.032325286, step = 18300 (24.070 sec)
I0916 22:59:41.511193 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.16146
I0916 22:59:41.513351 139906052065152 basic_session_run_hooks.py:260] loss = 0.035856407, step = 18400 (24.029 sec)
I0916 23:00:04.833770 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28769
I0916 23:00:04.836466 139906052065152 basic_session_run_hooks.py:260] loss = 0.032448843, step = 18500 (23.323 sec)
I0916 23:00:28.564483 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21395
I0916 23:00:28.567594 139906052065152 basic_session_run_hooks.py:260] loss = 0.030928398, step = 18600 (23.731 sec)
I0916 23:00:52.341335 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.20578
I0916 23:00:52.343905 139906052065152 basic_session_run_hooks.py:260] loss = 0.05181666, step = 18700 (23.776 sec)
I0916 23:01:15.775322 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2673
I0916 23:01:15.780152 139906052065152 basic_session_run_hooks.py:260] loss = 0.03251096, step = 18800 (23.436 sec)
I0916 23:01:39.349349 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24198
I0916 23:01:39.353173 139906052065152 basic_session_run_hooks.py:260] loss = 0.038782924, step = 18900 (23.573 sec)
I0916 23:02:02.729605 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 19000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
:::MLPv0.5.0 transformer 1568674923.642383099 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 23:02:03.642421 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674923.642383099 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 23:02:03.642720 139906052065152 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*
I0916 23:02:03.644604 139906052065152 problem.py:644] partition: 0 num_data_files: 1
I0916 23:02:03.875725 139906052065152 estimator.py:1145] Calling model_fn.
:::MLPv0.5.0 transformer 1568674924.353207111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 23:02:04.353243 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674924.353207111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 23:02:04.353535 139906052065152 t2t_model.py:1905] Setting T2TModel mode to 'eval'
I0916 23:02:04.353763 139906052065152 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0
I0916 23:02:04.353930 139906052065152 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0
I0916 23:02:04.354046 139906052065152 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0
I0916 23:02:04.354126 139906052065152 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0
I0916 23:02:04.354266 139906052065152 t2t_model.py:1905] Setting hparams.dropout to 0.0
I0916 23:02:04.354345 139906052065152 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0
:::MLPv0.5.0 transformer 1568674924.463913918 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
W0916 23:02:04.484138 139906052065152 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7f3e3316d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.
I0916 23:02:04.466480 139906052065152 api.py:452] :::MLPv0.5.0 transformer 1568674924.463913918 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
I0916 23:02:04.485002 139906052065152 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 23:02:04.581197 139906052065152 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_17594_256.bottom
I0916 23:02:04.803683 139906052065152 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_17594_256.targets_bottom
I0916 23:02:04.832741 139906052065152 t2t_model.py:1905] Building model body
:::MLPv0.5.0 transformer 1568674924.930016994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
I0916 23:02:04.930046 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674924.930016994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568674924.931938887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
I0916 23:02:04.931955 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674924.931938887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568674924.933568001 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
I0916 23:02:04.933584 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674924.933568001 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568674924.935137033 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 23:02:04.935153 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674924.935137033 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674925.243483067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 23:02:05.243515 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674925.243483067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568674925.245197058 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 23:02:05.245213 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674925.245197058 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674925.246783972 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 23:02:05.246798 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674925.246783972 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568674926.260808945 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 23:02:06.260852 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674926.260808945 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568674926.262564898 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 23:02:06.262581 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674926.262564898 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674926.264060020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 23:02:06.264075 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674926.264060020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568674926.372488022 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
I0916 23:02:06.372509 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674926.372488022 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
:::MLPv0.5.0 transformer 1568674926.493072033 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
I0916 23:02:06.493113 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674926.493072033 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568674926.495007992 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
I0916 23:02:06.495023 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674926.495007992 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568674926.496776104 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
I0916 23:02:06.496792 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674926.496776104 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568674926.498325109 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 23:02:06.498341 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674926.498325109 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674927.043987989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 23:02:07.044018 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674927.043987989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568674927.045896053 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 23:02:07.045911 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674927.045896053 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674927.047554016 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 23:02:07.047569 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674927.047554016 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568674927.669518948 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 23:02:07.669580 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674927.669518948 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568674927.671308994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 23:02:07.671340 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674927.671308994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568674927.673017979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 23:02:07.673033 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674927.673017979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568674927.757214069 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 23:02:07.757241 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568674927.757214069 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 23:02:07.791615 139906052065152 t2t_model.py:1905] Transforming body output with symbol_modality_17594_256.top
I0916 23:02:08.651971 139906052065152 estimator.py:1147] Done calling model_fn.
I0916 23:02:08.672831 139906052065152 evaluation.py:255] Starting evaluation at 2019-09-16T23:02:08Z
I0916 23:02:09.477349 139906052065152 monitored_session.py:240] Graph was finalized.
2019-09-16 23:02:09.478314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:02:09.479050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-09-16 23:02:09.479158: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 23:02:09.479207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 23:02:09.479250: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-16 23:02:09.479293: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-16 23:02:09.479332: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-16 23:02:09.479369: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-16 23:02:09.479405: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 23:02:09.479520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:02:09.480199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:02:09.480809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 23:02:09.480869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 23:02:09.480890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 23:02:09.480904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 23:02:09.481045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:02:09.481729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:02:09.482319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
I0916 23:02:09.484793 139906052065152 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-19000
I0916 23:02:10.005692 139906052065152 session_manager.py:500] Running local_init_op.
I0916 23:02:10.097150 139906052065152 session_manager.py:502] Done running local_init_op.
I0916 23:02:13.976515 139906052065152 evaluation.py:167] Evaluation [10/100]
I0916 23:02:15.937810 139906052065152 evaluation.py:167] Evaluation [20/100]
I0916 23:02:17.574769 139906052065152 evaluation.py:275] Finished evaluation at 2019-09-16-23:02:17
I0916 23:02:17.575114 139906052065152 estimator.py:2039] Saving dict for global step 19000: global_step = 19000, loss = 0.12452251, metrics-translate_enasl/targets/accuracy = 0.990817, metrics-translate_enasl/targets/accuracy_per_sequence = 0.88948655, metrics-translate_enasl/targets/accuracy_top5 = 0.9971664, metrics-translate_enasl/targets/approx_bleu_score = 0.9145865, metrics-translate_enasl/targets/neg_log_perplexity = -0.10970422, metrics-translate_enasl/targets/rouge_2_fscore = 0.93398035, metrics-translate_enasl/targets/rouge_L_fscore = 0.9363025
I0916 23:02:17.575840 139906052065152 estimator.py:2099] Saving 'checkpoint_path' summary for global step 19000: /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-19000
I0916 23:02:17.853025 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 2.59715
I0916 23:02:17.855500 139906052065152 basic_session_run_hooks.py:260] loss = 0.080027714, step = 19000 (38.502 sec)
I0916 23:02:41.281259 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.26835
I0916 23:02:41.284132 139906052065152 basic_session_run_hooks.py:260] loss = 0.034520242, step = 19100 (23.429 sec)
I0916 23:03:04.775207 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25643
I0916 23:03:04.777698 139906052065152 basic_session_run_hooks.py:260] loss = 0.035014626, step = 19200 (23.494 sec)
I0916 23:03:28.100955 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.28712
I0916 23:03:28.103728 139906052065152 basic_session_run_hooks.py:260] loss = 0.13260724, step = 19300 (23.326 sec)
I0916 23:03:51.514683 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.27099
I0916 23:03:51.517342 139906052065152 basic_session_run_hooks.py:260] loss = 0.03994792, step = 19400 (23.414 sec)
I0916 23:04:14.933351 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2701
I0916 23:04:14.937094 139906052065152 basic_session_run_hooks.py:260] loss = 0.031765364, step = 19500 (23.420 sec)
I0916 23:04:38.407841 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25993
I0916 23:04:38.410638 139906052065152 basic_session_run_hooks.py:260] loss = 0.034070317, step = 19600 (23.474 sec)
I0916 23:05:02.229481 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.19788
I0916 23:05:02.233246 139906052065152 basic_session_run_hooks.py:260] loss = 0.030235372, step = 19700 (23.823 sec)
I0916 23:05:25.851653 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23331
I0916 23:05:25.854526 139906052065152 basic_session_run_hooks.py:260] loss = 0.039588835, step = 19800 (23.621 sec)
I0916 23:05:49.608186 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.20936
I0916 23:05:49.611463 139906052065152 basic_session_run_hooks.py:260] loss = 0.044422254, step = 19900 (23.757 sec)
I0916 23:06:12.972058 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 20000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
W0916 23:06:13.193027 139906052065152 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
I0916 23:06:14.000641 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 23:06:14.223397 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.06253
I0916 23:06:14.225302 139906052065152 basic_session_run_hooks.py:260] loss = 0.030515067, step = 20000 (24.614 sec)
I0916 23:06:37.855990 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23146
I0916 23:06:37.858887 139906052065152 basic_session_run_hooks.py:260] loss = 0.029205257, step = 20100 (23.634 sec)
I0916 23:07:01.817109 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.17341
I0916 23:07:01.819247 139906052065152 basic_session_run_hooks.py:260] loss = 0.03004468, step = 20200 (23.960 sec)
I0916 23:07:25.308247 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25693
I0916 23:07:25.311086 139906052065152 basic_session_run_hooks.py:260] loss = 0.034469694, step = 20300 (23.492 sec)
I0916 23:07:48.808303 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25531
I0916 23:07:48.810853 139906052065152 basic_session_run_hooks.py:260] loss = 0.032703295, step = 20400 (23.500 sec)
I0916 23:08:12.621452 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.19936
I0916 23:08:12.624351 139906052065152 basic_session_run_hooks.py:260] loss = 0.046210308, step = 20500 (23.813 sec)
I0916 23:08:36.203071 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24059
I0916 23:08:36.205656 139906052065152 basic_session_run_hooks.py:260] loss = 0.03955091, step = 20600 (23.581 sec)
I0916 23:09:00.159454 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.17426
I0916 23:09:00.163340 139906052065152 basic_session_run_hooks.py:260] loss = 0.037671946, step = 20700 (23.958 sec)
I0916 23:09:23.718787 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24459
I0916 23:09:23.721070 139906052065152 basic_session_run_hooks.py:260] loss = 0.052835014, step = 20800 (23.558 sec)
I0916 23:09:47.500025 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.205
I0916 23:09:47.502598 139906052065152 basic_session_run_hooks.py:260] loss = 0.03254149, step = 20900 (23.781 sec)
I0916 23:10:11.365432 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 21000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 23:10:12.322912 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 23:10:12.559114 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 3.99057
I0916 23:10:12.561197 139906052065152 basic_session_run_hooks.py:260] loss = 0.032199282, step = 21000 (25.059 sec)
I0916 23:10:36.520838 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.17334
I0916 23:10:36.523087 139906052065152 basic_session_run_hooks.py:260] loss = 0.049073808, step = 21100 (23.962 sec)
I0916 23:10:59.993128 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.26033
I0916 23:10:59.995398 139906052065152 basic_session_run_hooks.py:260] loss = 0.11576795, step = 21200 (23.472 sec)
I0916 23:11:23.587641 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23829
I0916 23:11:23.591320 139906052065152 basic_session_run_hooks.py:260] loss = 0.03376567, step = 21300 (23.596 sec)
I0916 23:11:47.206199 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23394
I0916 23:11:47.208112 139906052065152 basic_session_run_hooks.py:260] loss = 0.04322572, step = 21400 (23.617 sec)
I0916 23:12:10.723751 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25216
I0916 23:12:10.727128 139906052065152 basic_session_run_hooks.py:260] loss = 0.03832392, step = 21500 (23.519 sec)
I0916 23:12:34.228053 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25453
I0916 23:12:34.230288 139906052065152 basic_session_run_hooks.py:260] loss = 0.034661196, step = 21600 (23.503 sec)
I0916 23:12:57.812336 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24012
I0916 23:12:57.815340 139906052065152 basic_session_run_hooks.py:260] loss = 0.037463464, step = 21700 (23.585 sec)
I0916 23:13:21.587318 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2061
I0916 23:13:21.594110 139906052065152 basic_session_run_hooks.py:260] loss = 0.023144234, step = 21800 (23.779 sec)
I0916 23:13:45.440238 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.19235
I0916 23:13:45.443360 139906052065152 basic_session_run_hooks.py:260] loss = 0.038924687, step = 21900 (23.849 sec)
I0916 23:14:08.815721 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 22000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
:::MLPv0.5.0 transformer 1568675649.745290995 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 23:14:09.745322 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675649.745290995 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
I0916 23:14:09.745661 139906052065152 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*
I0916 23:14:09.747442 139906052065152 problem.py:644] partition: 0 num_data_files: 1
I0916 23:14:09.977942 139906052065152 estimator.py:1145] Calling model_fn.
:::MLPv0.5.0 transformer 1568675650.420066118 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 23:14:10.420104 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675650.420066118 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 17594, "hidden_size": 256}
I0916 23:14:10.420443 139906052065152 t2t_model.py:1905] Setting T2TModel mode to 'eval'
I0916 23:14:10.420682 139906052065152 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0
I0916 23:14:10.420842 139906052065152 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0
I0916 23:14:10.420949 139906052065152 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0
I0916 23:14:10.421040 139906052065152 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0
I0916 23:14:10.421138 139906052065152 t2t_model.py:1905] Setting hparams.dropout to 0.0
I0916 23:14:10.421236 139906052065152 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0
:::MLPv0.5.0 transformer 1568675650.533458948 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
W0916 23:14:10.559079 139906052065152 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7f3e3316d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.
I0916 23:14:10.536422 139906052065152 api.py:452] :::MLPv0.5.0 transformer 1568675650.533458948 (/tmp/tmpbSJbuo.py:100) model_hp_initializer_gain: 1.0
I0916 23:14:10.560157 139906052065152 api.py:255] Using variable initializer: uniform_unit_scaling
I0916 23:14:10.655823 139906052065152 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_17594_256.bottom
I0916 23:14:10.841809 139906052065152 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_17594_256.targets_bottom
I0916 23:14:10.868880 139906052065152 t2t_model.py:1905] Building model body
:::MLPv0.5.0 transformer 1568675650.969691038 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
I0916 23:14:10.969723 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675650.969691038 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568675650.971787930 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
I0916 23:14:10.971803 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675650.971787930 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568675650.973697901 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
I0916 23:14:10.973712 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675650.973697901 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568675650.975368977 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 23:14:10.975384 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675650.975368977 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568675651.900257111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 23:14:11.900294 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675651.900257111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568675651.902259111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 23:14:11.902281 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675651.902259111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568675651.903995991 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 23:14:11.904011 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675651.903995991 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568675652.310167074 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 23:14:12.310198 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675652.310167074 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568675652.311940908 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 23:14:12.311958 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675652.311940908 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568675652.313479900 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
I0916 23:14:12.313496 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675652.313479900 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568675652.425276995 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
I0916 23:14:12.425308 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675652.425276995 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {"hidden_size": 256}
:::MLPv0.5.0 transformer 1568675652.542318106 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
I0916 23:14:12.542345 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675652.542318106 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1568675652.544157982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
I0916 23:14:12.544173 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675652.544157982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1568675652.545737028 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
I0916 23:14:12.545752 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675652.545737028 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1568675652.547255993 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
I0916 23:14:12.547271 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675652.547255993 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"num_heads": 4, "use_bias": "false", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568675653.102178097 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 23:14:13.102238 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675653.102178097 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568675653.105920076 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 23:14:13.105943 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675653.105920076 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568675653.109308004 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 23:14:13.109332 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675653.109308004 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568675653.734102011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
I0916 23:14:13.734132 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675653.734102011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 1024, "activation": "relu", "use_bias": "True"}
:::MLPv0.5.0 transformer 1568675653.735888958 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
I0916 23:14:13.735905 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675653.735888958 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"use_bias": "True", "hidden_size": 256}
:::MLPv0.5.0 transformer 1568675653.737596035 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
I0916 23:14:13.737611 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675653.737596035 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1568675653.821551085 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 23:14:13.821578 139906052065152 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568675653.821551085 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 256}
I0916 23:14:13.855598 139906052065152 t2t_model.py:1905] Transforming body output with symbol_modality_17594_256.top
I0916 23:14:15.191127 139906052065152 estimator.py:1147] Done calling model_fn.
I0916 23:14:15.212573 139906052065152 evaluation.py:255] Starting evaluation at 2019-09-16T23:14:15Z
I0916 23:14:15.503524 139906052065152 monitored_session.py:240] Graph was finalized.
2019-09-16 23:14:15.504459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:14:15.505238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
2019-09-16 23:14:15.505342: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-16 23:14:15.505370: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-16 23:14:15.505401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-16 23:14:15.505426: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-16 23:14:15.505448: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-16 23:14:15.505470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-16 23:14:15.505493: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-16 23:14:15.505597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:14:15.506319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:14:15.506911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-16 23:14:15.506965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-16 23:14:15.506980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-16 23:14:15.506991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-16 23:14:15.507118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:14:15.507801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-16 23:14:15.508442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
I0916 23:14:15.511266 139906052065152 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-22000
I0916 23:14:15.986675 139906052065152 session_manager.py:500] Running local_init_op.
I0916 23:14:16.075033 139906052065152 session_manager.py:502] Done running local_init_op.
I0916 23:14:20.090410 139906052065152 evaluation.py:167] Evaluation [10/100]
I0916 23:14:22.038532 139906052065152 evaluation.py:167] Evaluation [20/100]
I0916 23:14:23.734679 139906052065152 evaluation.py:275] Finished evaluation at 2019-09-16-23:14:23
I0916 23:14:23.735034 139906052065152 estimator.py:2039] Saving dict for global step 22000: global_step = 22000, loss = 0.122706495, metrics-translate_enasl/targets/accuracy = 0.99134177, metrics-translate_enasl/targets/accuracy_per_sequence = 0.89144254, metrics-translate_enasl/targets/accuracy_top5 = 0.99737626, metrics-translate_enasl/targets/approx_bleu_score = 0.9163796, metrics-translate_enasl/targets/neg_log_perplexity = -0.106168106, metrics-translate_enasl/targets/rouge_2_fscore = 0.93455213, metrics-translate_enasl/targets/rouge_L_fscore = 0.9370907
I0916 23:14:23.735922 139906052065152 estimator.py:2099] Saving 'checkpoint_path' summary for global step 22000: /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt-22000
I0916 23:14:23.970154 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 2.59539
I0916 23:14:23.973017 139906052065152 basic_session_run_hooks.py:260] loss = 0.026876427, step = 22000 (38.530 sec)
I0916 23:14:47.674158 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.21869
I0916 23:14:47.676373 139906052065152 basic_session_run_hooks.py:260] loss = 0.043201156, step = 22100 (23.703 sec)
I0916 23:15:11.201894 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.2503
I0916 23:15:11.203911 139906052065152 basic_session_run_hooks.py:260] loss = 0.041364484, step = 22200 (23.528 sec)
I0916 23:15:34.840758 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.23034
I0916 23:15:34.843888 139906052065152 basic_session_run_hooks.py:260] loss = 0.032016397, step = 22300 (23.640 sec)
I0916 23:15:58.101629 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.29906
I0916 23:15:58.103998 139906052065152 basic_session_run_hooks.py:260] loss = 0.036617607, step = 22400 (23.260 sec)
I0916 23:16:21.547280 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.26517
I0916 23:16:21.549675 139906052065152 basic_session_run_hooks.py:260] loss = 0.083037734, step = 22500 (23.446 sec)
I0916 23:16:45.089905 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.24763
I0916 23:16:45.092233 139906052065152 basic_session_run_hooks.py:260] loss = 0.054597575, step = 22600 (23.543 sec)
I0916 23:17:09.113038 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.16264
I0916 23:17:09.115268 139906052065152 basic_session_run_hooks.py:260] loss = 0.03162928, step = 22700 (24.023 sec)
I0916 23:17:32.500416 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.27581
I0916 23:17:32.502448 139906052065152 basic_session_run_hooks.py:260] loss = 0.030808141, step = 22800 (23.387 sec)
I0916 23:17:56.164000 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.22592
I0916 23:17:56.167126 139906052065152 basic_session_run_hooks.py:260] loss = 0.035879504, step = 22900 (23.665 sec)
I0916 23:18:19.776978 139906052065152 basic_session_run_hooks.py:606] Saving checkpoints for 23000 into /content/t2t_train/translate_enasl/transformer-transformer_small#_single_gpu/model.ckpt.
I0916 23:18:20.682404 139906052065152 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).
I0916 23:18:20.921627 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.03915
I0916 23:18:20.923316 139906052065152 basic_session_run_hooks.py:260] loss = 0.045450907, step = 23000 (24.756 sec)
I0916 23:18:44.449479 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.25028
I0916 23:18:44.452018 139906052065152 basic_session_run_hooks.py:260] loss = 0.03484403, step = 23100 (23.529 sec)
I0916 23:19:07.870395 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.26969
I0916 23:19:07.873528 139906052065152 basic_session_run_hooks.py:260] loss = 0.02266557, step = 23200 (23.421 sec)
I0916 23:19:31.786017 139906052065152 basic_session_run_hooks.py:692] global_step/sec: 4.18138
I0916 23:19:31.788834 139906052065152 basic_session_run_hooks.py:260] loss = 0.032014765, step = 23300 (23.915 sec)
Traceback (most recent call last):
  File "/usr/local/bin/t2t-trainer", line 33, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/usr/local/lib/python2.7/dist-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/usr/local/lib/python2.7/dist-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/usr/local/bin/t2t-trainer", line 28, in main
    t2t_trainer.main(argv)
  File "/usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py", line 387, in main
    execute_schedule(exp)
  File "/usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py", line 349, in execute_schedule
    getattr(exp, FLAGS.schedule)()
  File "/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py", line 438, in continuous_train_and_eval
    self._eval_spec)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/training.py", line 473, in train_and_evaluate
    return executor.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/training.py", line 613, in run
    return self.run_local()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/training.py", line 714, in run_local
    saving_listeners=saving_listeners)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py", line 367, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py", line 1158, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py", line 1192, in _train_model_default
    saving_listeners)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py", line 1484, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 754, in run
    run_metadata=run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 1252, in run
    run_metadata=run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 1338, in run
    return self._sess.run(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 1411, in run
    run_metadata=run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 1169, in run
    return self._sess.run(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 950, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1350, in _do_run
    run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1356, in _do_call
    return fn(*args)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1429, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
